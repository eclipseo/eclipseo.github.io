<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="generator" content="ReText 7.0.0">
<link rel="stylesheet" media="screen" href="style.css" type="text/css" />
<title>Report</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  jax: ["input/TeX", "output/HTML-CSS", "output/NativeMML"],
  extensions: ["MathMenu.js", "MathZoom.js"],
  TeX: {
    equationNumbers: {autoNumber: "AMS"}
  }
});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script></head>
<body>
<h1>Image formats comparison</h1>
<h2>Introduction</h2>
<p>This study compares 7 differents encoders, AOM AV1, HEIF X265, JPEG XL, WebP and WebP2. We use five algorithms in order to compare each format:</p>
<ul>
<li>SSimulacra: Structural SIMilarity Unveiling Local And Compression Related Artifacts. This is a perceptual metric designed specifically for scoring image compression related artifacts in a way that correlates well with human opinions.</li>
<li>DSSIM: Image similarity comparison simulating human perception, based on multiscale SSIM.</li>
<li>Butteraugli: project that estimates the psychovisual similarity of two images.</li>
<li>SSIM: Structural Similarity algorithm</li>
<li>MSSIM: Multi-Scale Structural Similarity algorithm</li>
<li>PSNR-HVS: Peak Signal to Noise Ratio taking into account Contrast Sensitivity Function (CSF) and between-coefficient contrast masking of DCT basis functions</li>
<li>CIEDE2000: a color-difference formula recommended by the CIE in year 2001</li>
<li>VMAF: Video Multi-Method Assessment Fusion: <a href="http://techblog.netflix.com/2016/06/toward-practical-perceptual-video.html">http://techblog.netflix.com/2016/06/toward-practical-perceptual-video.html</a></li>
</ul>
<h2>Materials</h2>
<h3>Image set</h3>
<p>The image set is comprised of 49 images from <a href="https://wiki.xiph.org/Daala_Quickstart#Test_Media">the subset 1 maintained by Xiph</a>. All images are RGB PNG.</p>
<h3>Codecs</h3>
<ul>
<li>Alliance for Open Media AVIF: <code>https://github.com/AOMediaCodec/libavif</code>. The version used is 0.9.2.</li>
<li>
<ul>
<li>AOM AV1: <code>https://aomedia.googlesource.com/aom/</code> The version used is v3.1.1 and git revision <code>70d2ea60e3ca5f11d4e153b140a72890c13b2f51</code>.</li>
</ul>
</li>
<li>Struktur AG HEIF: <code>https://github.com/strukturag/libheif</code>. The version used is 1.12.0, with x265 3.5+1-f0c1022b6.</li>
<li>Mozilla JPEG: <code>https://github.com/mozilla/mozjpeg</code>. The version used is 4.0.3.</li>
<li>JPEG XL: <code>https://github.com/libjxl/libjxl</code>. The version used is 0.3.7 and git revision <code>b1f80161cfc3c0ba4024cd7d5d14bb74061ee7bf</code>.</li>
<li>Google WebP: <code>https://chromium.googlesource.com/webm/libwebp</code>. The version used is 1.2.0.</li>
<li>Google WebP2: <code>https://chromium.googlesource.com/codecs/libwebp2/</code>. The version used is built from GIT revision <code>3724e165a6df9260eb30b9a731a9f9594d3c5703</code> and git revision <code>09c86afba566d92bbef5318872c1662bf9ddec6b</code>.</li>
</ul>
<h3>Metrics</h3>
<ul>
<li>The VMAF (Video Multi-Method Assessment Fusion) metric, MSSIM, SSIM, CIEDE2000 and PNSR-HVS are computed using <code>vmaf</code>, provided by Netflix: <code>https://github.com/Netflix/vmaf</code>. The version used is 2.2.0. Each metric compares two Y4M files.</li>
<li>SSImulacra: <code>https://github.com/libjxl/libjxl/tree/main/tools</code> The version used is built from version 0.3.7.</li>
<li>DSSIM: <code>https://github.com/kornelski/dssim</code> The version used is 3.1.0.</li>
<li>BUtteraugli: <code>https://github.com/libjxl/libjxl/tree/main/tools</code> The version used is built from  from version 0.3.7.</li>
</ul>
<h3>Tools</h3>
<ul>
<li><code>ffmpeg</code> is used for image formats conversion. The version used is ffmpeg 4.4.</li>
<li>ImageMagick <code>identify</code> is used to determine the width and height of images. The version used is ImageMagick 6.9.11-27.</li>
<li>Python 3 timeit is used to mesure computing times.</li>
<li>Python 3 Pandas and Numpy are used to compute means.</li>
<li>Python 3 Matplot is used to plot graphs.</li>
</ul>
<h2>Methods</h2>
<h3>Image compression</h3>
<p>All images are compressed losslessly and over a range of qualities for each codec:</p>
<ul>
<li>
<p>AOM 3.1.1:</p>
<ul>
<li>lossless: <code>avifenc --lossless -c aom -s d -o [output] [input(PNG)]</code></li>
<li>between q=4 and q=63: <code>avifenc -a end-usage=q -a tune=butteraugli -a sharpness=3 --min 0 --max 63 -a cq-level=$quality -o [output] [input(PNG)]</code></li>
</ul>
</li>
<li>
<p>AOM 20210715:</p>
<ul>
<li>lossless: <code>avifenc --lossless -c aom -s d -o [output] [input(PNG)]</code></li>
<li>between q=4 and q=63: <code>avifenc -a end-usage=q -a tune=butteraugli -a sharpness=3 --min 0 --max 63 -a cq-level=$quality -o [output] [input(PNG)]</code></li>
</ul>
</li>
<li>
<p>HEIF 1.12.0:</p>
<ul>
<li>lossless: <code>heif-enc -L -p chroma=444 --matrix_coefficients=0 -o [output] [input(PNG)]</code></li>
<li>between q=1 and q=100: <code>heif-enc -p chroma=444 --matrix_coefficients=0 --quality  [output] [input(PNG)]</code></li>
</ul>
</li>
<li>
<p>JPEG XL 0.3.7:</p>
<ul>
<li>lossless: <code>cjxl [input(PNG)] [output] -v -q $quality</code></li>
<li>between q=8 and q=100: <code>cjxl [input(PNG)] [output] -v -q 100</code></li>
</ul>
</li>
<li>
<p>JPEG XL 20210715:</p>
<ul>
<li>lossless: <code>cjxl [input(PNG)] [output] -v -q $quality</code></li>
<li>between q=8 and q=100: <code>cjxl [input(PNG)] [output] -v -q 100</code></li>
</ul>
</li>
<li>
<p>MozJPEG 4.0.3:</p>
<ul>
<li>lossless: <code>cjpeg -rgb -quality 100 [input(PNG)] &gt; [output]</code></li>
<li>between q=5 and q=95: <code>cjpeg -quality $quality [input(PNG)] &gt; [output]</code></li>
</ul>
</li>
<li>
<p>WebP 1.2.0:</p>
<ul>
<li>lossless: <code>cwebp -mt -z 9 -lossless -o [output] [input(PNG)]</code></li>
<li>between q=5 and q=95: <code>cwebp -mt -q $quality -o [output] [input(PNG)]</code></li>
</ul>
</li>
<li>
<p>WebP2 20201204:</p>
<ul>
<li>lossless: <code>cwp2 -mt 2 -uv_mode 2 -q 100 -o [output] [input(PNG)]</code></li>
<li>between q=5 and q=95: <code>cwp2 -mt 2 -uv_mode 2 -q $quality -o [output] [input(PNG)]</code></li>
</ul>
</li>
</ul>
<p>The Python script used to generate the compressed images are available on <a href="https://github.com/eclipseo/image-comparison-sources">the GIT repository</a>.</p>
<h3>Image selection</h3>
<p>The images which will be displayed on the website are then chosen among all compressed images, using the following criteria:</p>
<ul>
<li>The MozJPEG file at quality 85 is chosen to be the reference filesize for <em>large</em> quality images.</li>
<li>The filesize for <em>big</em> quality images is 125% of the <em>large</em> filesize.</li>
<li>The filesize for <em>medium</em> quality images is 60% of the <em>large</em> filesize.</li>
<li>The filesize for <em>small</em> quality images is 60% of the <em>medium</em> filesize.</li>
<li>The filesize for <em>tiny</em> quality images is 60% of the <em>small</em> filesize.</li>
</ul>
<p>The Python script used to select the compressed images are available on <a href="https://github.com/eclipseo/image-comparison-sources">the GIT repository</a>.</p>
<h3>Encoding and decoding speeds:</h3>
<h4>Lossless compression and speed</h4>
<p>For each codec and image, the encoding and decoding speeds for lossless compression are sampled using Python <code>timeit</code>.
The arithmetic mean of encoding and decoding speeds are calculated over the entire image set. We then determine a <a href="https://en.wikipedia.org/wiki/Weissman_score">Weissman score</a> for each codec using the following formula:</p>
<p>
<script type="math/tex; mode=display">W = \alpha {r \over \overline{r}} {\log{\overline{T}} \over \log{T}}</script>
</p>
<p>where <code>r</code> is the compression ratio over PNG filesize, <code>T</code> the time required to compress, <code>̅r</code> and <code>̅T</code> the same metrics for the standard compressor, and alpha is a scaling constant.</p>
<p>The standard compressor used is the compression of a JPG image using mozjpeg.</p>
<h3>Lossy metrics</h3>
<p>For each codec and image, we apply the following metrics, SSimulacra, DSSIM, Butteraugli, SSIM, CIEDE2000, MSSSIM, PSNR-HVS-M and VMAF, over image samples of increasing quality. For VMAF, we use the trained model <code>vmaf_v0.6.1</code> given by Netflix.</p>
<p>For SSimulacra and DSSIM, Butteraugli, we first decode the compressed image to PNG then we apply the metrics over each sample, comparing it to the original image.</p>
<p>For SSIM, CIEDE2000, MSSSIM, PSNR-HVS-M and VMAF, on each sample, we first decode the compressed image to PNG, then export the resulting file to 4:2:0 Y4M using FFMPEG (<code>ffmpeg -y -i  [input] -pix_fmt yuv444p -vf scale=in_range=full:out_range=full [output]</code>). Finally we apply the metrics over each sample, comparing it to the original image.</p>
<p>For each codec, we calculate the arithmetic mean of each metric over the entire set of images, weighted by the area of the corresponding picture, for the samples of increasing quality:</p>
<p>
<script type="math/tex; mode=display">\overline{metric}_{quality\ q} = \frac{ \sum\limits_{picture=1}^{50} metric_{qp} \times area_{p}}{\sum\limits_{p=1}^{50} area_{p}}</script>
</p>
<p>We also determine the average bits per pixel for each quality sample:</p>
<p>
<script type="math/tex; mode=display">\overline{bpp}_{quality\ q} = \frac{ \sum\limits_{picture=1}^{50} filesize_{qp}}{\sum\limits_{picture=1}^{50} area_{p}}</script>
</p>
<h2>Results</h2>
<h3>Raw data</h3>
<p>The following archives contain the raw data in csv format for subset1 and subset2:</p>
<ul>
<li><a href="subset1.tar.gz">Subset1</a> (updated July 2021)</li>
</ul>
<h3>Lossless compression ratio and Weissman score:</h3>
<table>
<thead>
<tr>
<th>format</th>
<th align="right">avg_bpp</th>
<th align="right">avg_compression_ratio</th>
<th align="right">avg_space_saving</th>
<th align="right">wavg_encode_time</th>
<th align="right">wavg_decode_time</th>
<th align="right">weissman_score</th>
</tr>
</thead>
<tbody>
<tr>
<td>heif_1.12.0</td>
<td align="right">9.931</td>
<td align="right">1.3219</td>
<td align="right">0.24354</td>
<td align="right">16.09</td>
<td align="right">5.4341</td>
<td align="right">1.3500</td>
</tr>
<tr>
<td>jxl_20210715</td>
<td align="right">10.097</td>
<td align="right">1.3002</td>
<td align="right">0.23088</td>
<td align="right">31.52</td>
<td align="right">3.0728</td>
<td align="right">1.2416</td>
</tr>
<tr>
<td>webp2_20210715</td>
<td align="right">10.266</td>
<td align="right">1.2789</td>
<td align="right">0.21807</td>
<td align="right">27.98</td>
<td align="right">6.3383</td>
<td align="right">1.2354</td>
</tr>
<tr>
<td>jxl_0.3.7</td>
<td align="right">10.097</td>
<td align="right">1.3002</td>
<td align="right">0.23088</td>
<td align="right">34.15</td>
<td align="right">3.3576</td>
<td align="right">1.2320</td>
</tr>
<tr>
<td>webp_1.2.0</td>
<td align="right">10.508</td>
<td align="right">1.2494</td>
<td align="right">0.19963</td>
<td align="right">82.57</td>
<td align="right">4.2148</td>
<td align="right">1.0916</td>
</tr>
<tr>
<td>webp2_20201204</td>
<td align="right">10.397</td>
<td align="right">1.2627</td>
<td align="right">0.20805</td>
<td align="right">93.47</td>
<td align="right">6.5015</td>
<td align="right">1.0912</td>
</tr>
<tr>
<td>mozjpeg</td>
<td align="right">13.959</td>
<td align="right">0.9405</td>
<td align="right">-0.06330</td>
<td align="right">10.96</td>
<td align="right">0.5793</td>
<td align="right">1.0000</td>
</tr>
<tr>
<td>aom_20210715</td>
<td align="right">11.656</td>
<td align="right">1.1263</td>
<td align="right">0.11215</td>
<td align="right">414.12</td>
<td align="right">4.3691</td>
<td align="right">0.8614</td>
</tr>
<tr>
<td>aom_3.1.1</td>
<td align="right">11.657</td>
<td align="right">1.1262</td>
<td align="right">0.11209</td>
<td align="right">507.02</td>
<td align="right">4.4280</td>
<td align="right">0.8480</td>
</tr>
</tbody>
</table>
<h3>Lossy compression and speed</h3>
<p><img class="graph" alt="Encoding time in function of bits per pixel" src="subset1.encoding_time.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>
<h2>Lossy metrics</h2>
<p>For each comparison algorithms, we plot the quality in dB or score in function of the mean bits per pixel on a logarithmic scale. We can then visualize which codec gives the best quality at a given bit per pixel (top left is better).</p>
<h3>Bits per pixel at equivalent quality according to SSimulacra</h3>
<p><img class="graph" alt="Bits per pixel at equivalent quality according to SSimulacra" src="subset1.ssimulacra.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>
<h3>Bits per pixel at equivalent quality according to DSSIM</h3>
<p><img class="graph" alt="Bits per pixel at equivalent quality according to DSSIM" src="subset1.dssim.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>
<h3>Bits per pixel at equivalent quality according to Butteraugli</h3>
<p><img class="graph" alt="Bits per pixel at equivalent quality according to Butteraugli" src="subset1.butteraugli.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>
<h3>Bits per pixel at equivalent quality according to PSNR-HVS</h3>
<p><img class="graph" alt="Bits per pixel at equivalent quality according to PSNR-HVS" src="subset1.psnr-hvs.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>
<h3>Bits per pixel at equivalent quality according to MSSSIM</h3>
<p><img class="graph" alt="Bits per pixel at equivalent quality according to MSSSIM" src="subset1.ms-ssim.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>
<h3>Bits per pixel at equivalent quality according to SSIM</h3>
<p><img class="graph" alt="Bits per pixel at equivalent quality according to SSIM" src="subset1.ssim.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>
<h3>Bits per pixel at equivalent quality according to CIEDE2000</h3>
<p><img class="graph" alt="Bits per pixel at equivalent quality according to CIEDE2000" src="subset1.ciede2000.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>
<h3>Bits per pixel at equivalent quality according to VMAF</h3>
<p>Please note that VMAF is more suitable as a video codec comparison tool, not an image one.</p>
<p><img class="graph" alt="Bits per pixel at equivalent quality according to VMAF" src="subset1.vmaf.(aom_20210715,jxl_20210715,mozjpeg,webp2_20210715,webp_1.2.0).svg"></p>

</body>
</html>
